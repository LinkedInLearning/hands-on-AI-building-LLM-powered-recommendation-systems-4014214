{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# install the necessary libraries\n",
        "\n",
        "!pip install evaluate rouge_score bert_score sentence_transformers"
      ],
      "metadata": {
        "id": "F5EmcTxXgtLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6__-RwEPgR9a",
        "outputId": "ced9a36a-4275-4aa6-dc84-8f756287c87d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data for Evaluation ---\n",
            "Candidate Generation: 'a durable jacket for hiking'\n",
            "Reference Text:       'a long-lasting coat for trekking'\n",
            "----------------------------- \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Import the main library\n",
        "import evaluate\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") # Hides a benign UserWarning from Sentence-BERT\n",
        "\n",
        "# Step 3: Define our candidate and reference sentences\n",
        "# The goal is to show the difference between lexical and semantic similarity.\n",
        "candidate_sentence = \"a durable jacket for hiking\"\n",
        "reference_sentence = \"a long-lasting coat for trekking\"\n",
        "\n",
        "# Notice that they mean almost the exact same thing, but use completely different words.\"\n",
        "print(\"--- Data for Evaluation ---\")\n",
        "print(f\"Candidate Generation: '{candidate_sentence}'\")\n",
        "print(f\"Reference Text:       '{reference_sentence}'\")\n",
        "print(\"-\" * 29, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Evaluate with ROUGE (Lexical, Recall-based)\n",
        "\n",
        "print(\"--- Evaluating with ROUGE (Lexical Recall) ---\")\n",
        "rouge_metric = evaluate.load('rouge')\n",
        "\n",
        "results_rouge = rouge_metric.compute(\n",
        "    predictions=[candidate_sentence],\n",
        "    references=[[reference_sentence]]\n",
        ")\n",
        "\n",
        "# Print the results\n",
        "print(\"ROUGE scores are low because there is very little word-for-word overlap.\")\n",
        "print(f\"ROUGE-L Score: {results_rouge['rougeL']:.4f}\")\n",
        "print(\"-\" * 46, \"\\n\")\n",
        "\n",
        "# Step 5: Evaluate with BLEU (Lexical, Precision-based)\n",
        "\n",
        "print(\"--- Evaluating with BLEU (Lexical Precision) ---\")\n",
        "bleu_metric = evaluate.load('bleu')\n",
        "\n",
        "# Compute the score\n",
        "results_bleu = bleu_metric.compute(\n",
        "    predictions=[candidate_sentence],\n",
        "    references=[[reference_sentence]]\n",
        ")\n",
        "\n",
        "# Print the results\n",
        "print(\"BLEU score is also low, as it relies on matching n-grams (phrases).\")\n",
        "print(f\"BLEU Score: {results_bleu['bleu']:.4f}\")\n",
        "print(\"-\" * 49, \"\\n\")\n",
        "\n",
        "\n",
        "# Step 6: Evaluate with BERTScore (Semantic)\n",
        "\n",
        "print(\"--- Evaluating with BERTScore (Semantic Similarity) ---\")\n",
        "bertscore_metric = evaluate.load('bertscore')\n",
        "\n",
        "# Compute the score\n",
        "# We specify a model type to ensure consistent results.\n",
        "results_bert = bertscore_metric.compute(\n",
        "    predictions=[candidate_sentence],\n",
        "    references=[[reference_sentence]],\n",
        "    model_type=\"distilbert-base-uncased\"\n",
        ")\n",
        "\n",
        "# BERTScore returns precision, recall, and F1. F1 is the harmonic mean and a great single-number summary.\n",
        "# We get the values from the list since we only passed one sentence pair.\n",
        "bert_f1_score = results_bert['f1'][0]\n",
        "\n",
        "print(\"BERTScore understands that 'durable' is similar to 'long-lasting' and 'jacket' is similar to 'coat'.\")\n",
        "print(f\"BERTScore F1-Score: {bert_f1_score:.4f}\")\n",
        "print(\"-\" * 55, \"\\n\")"
      ],
      "metadata": {
        "id": "m2ZGD6zcgkA6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605,
          "referenced_widgets": [
            "ba55fb56055c4fa5a35b4a0feae1b920",
            "9ca4095b29e34be38fe654e53e324c60",
            "104abdd666e348a1a3c2457d9c222adc",
            "0b5c0fa451764b1f85f830d9a0bd284e",
            "1c3e27c4738646219b44d8242019f096",
            "0cf835c016f9419c98bf9793ba2fbd14",
            "e021fa7919c04e5cace9bc0a124cbe43",
            "a876a6264c2d47bb90403a0df7a2bd96",
            "aa44bd4b7f244a27a581af1bb7feb6aa",
            "6e90ad3757914ab2ae46c7654335740f",
            "5439d69f8066491f9a996851ac81714b",
            "6e0fb29376aa4949b6890561c9495a97",
            "e09afb35ad964c689c8c1f7ad885e79c",
            "9f5aca5d47374c84b59ce06a6f40fd4d",
            "66b2bba781c1474588a6bf78cea640a1",
            "4d95210996914ec1a360bb5ae07d94e4",
            "4201a1a44d954a08921304ea588bf711",
            "7ff02e94eec24e388979812f4840a539",
            "9da8eb84bb174b6aa8fac1796af04b59",
            "24a3a62d57a14cc19eff5d5ff4526ad3",
            "f8d26c40666a428b82e45d00a6321303",
            "0450095bc4de49fa818644b2154639ee",
            "3de9e1b29ac34fef9d4105093cad6977",
            "1bb3be0f581045679d1713efaca9fe75",
            "7d707c76ba0f456c958c558dc4ae61fa",
            "4fd4995d9d6d47979e66cfa468c3fa6d",
            "7552851a3e154da496f95219219b8075",
            "54e2d6e1f14f4b0cbebeda15da36f403",
            "c5fbc9130367477f8845e9ffd5d2907a",
            "88059b41d7eb48bb83f95d20c40ee6aa",
            "1ff7b57ad68644598806b687c65b3c54",
            "6f3afef8d1184e669306b5f0bd0f53ce",
            "7822aa2ba59c49628682caf51814b26b",
            "eb0194b39486497195c1fd8c86c30787",
            "dc472505c14a4ca0be563608be9f6139",
            "e8d13af6f8104261be7f65a12d7ee260",
            "68f22a4b77fe4a3ca7775d2ed73ea93e",
            "d4074411f6bd4fb5aacbacb11273cad6",
            "19d9946ea3764b17a90d5dc604d42986",
            "a1640ecbf0b24ce8a8db08da19533e9c",
            "38452a9dbf55439d80747fdd46a2bd69",
            "04a2078c56df4a208c6d578a8d4f8f4e",
            "bcca14ad79384059812e1e5232d1ab14",
            "2ec71efbd3d142e4b02b365eaa3d12d7",
            "d2347b66f3c74b8ea4ae0059a24ad5f4",
            "7de894f095664a7d8da4622e50747e28",
            "698c620702eb4aeebf38787b413dae14",
            "22af658558974d3ca2e6efe64f1b2842",
            "7e39c1bd66d644f6991cec916091459c",
            "be0365705f7e418b8d7be9fb90553619",
            "38ecf7f1dfe747d980fc406c8ff26307",
            "4e055a6d33ba4b829761b2f1e8f267f1",
            "94fd1b724df94596ad8c94ad1e028c54",
            "728faa4069a4491d9ff6cc1b89e15ce4",
            "8a6ad10725e340de9acb1cbd235e0ab7",
            "52253fc37c124746a27b1aa612e7872d",
            "c73201cae73945249a748e41d36302d0",
            "63ea16b3e45046ae8a327226cc241332",
            "aa32a65176c04da9bf3f31abc71f5274",
            "2dd131ddad674db1a37b1568ac8cf332",
            "66baf523d60248518934470b4b148759",
            "02baec9da7eb40fcb3ebd3c352f4a1f2",
            "2b27660eda614ba4be7a4af77b1aa3b2",
            "cf1f95122b794a138563ff1ffb04a0f0",
            "de0f3892b5c24cbb9dcbd6771a8cf8b3",
            "bda7765b73a44754b1a3c054ddd0f110",
            "b17cd9d6ab644cdca7393d41888c7505",
            "f9e0e027d623494da2f16bb7678cacb3",
            "eeab4cba3df140e6a5509f9e025e8653",
            "6dac6ea401d846899d5c1a587088d753",
            "c92cce468b2f40d0a57038a912636719",
            "7a72600676da45739ed79999873ec475",
            "d6ed400f1bd34fd9a84a1cb21a8aba93",
            "756b409db5844c9fa74b8fa20323e8ec",
            "ee040167201b49ea8aa2312ffb6fbd16",
            "95a490d4a3e34d0d9ae625a27a6d8894",
            "add51e62aa864ebea9dc5df6c4c06272",
            "563e113b046a4aeaa9b4dcefe43603bd",
            "272a5046b4e04f79b667693e862cd72b",
            "4249c8544b05451b86cf21af18049462",
            "fccdde92ccd946db9b80b3f14702197d",
            "c4d3103e9b9046409ce7f0d442e73446",
            "70aa6b83267249a2a89f3340fa1ae49b",
            "a386aef3273a409ca9164713d5ef0b16",
            "f17e338e88f34543969602500cc84d72",
            "27e11f29ad8344d18041d562f6be6796",
            "5e5d352474f341209858b1a435b18af6",
            "c6460af2434841798c66044b330dfc7a",
            "e5b459622b8e428bac98feb33820302b",
            "134c3b1e038947b2a44cafdf6711447b",
            "4c3880da4e1a4ab7a24cd96f23342cf9",
            "038797c9cafc4755ae093879ec31c175",
            "e977b05681b54c08949c1da410c64def",
            "4a9aa16b81ac45569bbd801dcbee9815",
            "7ad5890f67714bbfb3ea17bee2ecd29c",
            "f22af526e412473888fbc04adc44eae2",
            "3a7ea1a3acfd418ebc635624e7efcffc",
            "dac73fae04e94ea3b33dccb68d6f83dd",
            "5b318dd2dd5249029484dba12fcae99a",
            "1d66efecc13a4df29b4a0568b0c6f3d6",
            "f463590ead6e4324b29cbcef4ec9f130",
            "bc3a6da6486444f5ad8e3056bd253c47",
            "35dd6216632a4c34886303d89e30c10d",
            "22ebf597c50a4a8391e21e3623f69bf1",
            "f3ec41213b25448ea0b6a6128e6c6b9d",
            "9ae2857c568340fa864d02a2db85654f",
            "cca58986080f4261900893da09ecfe66",
            "4757341bff2445ce8889382e949b29c9",
            "2eebe42f5e5f4db192841d5402468568",
            "bf9d125f2a53417391b8ed6ba9f20d7b"
          ]
        },
        "outputId": "8e474cbb-ad7e-45cc-d048-c410a3287e4a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Evaluating with ROUGE (Lexical Recall) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba55fb56055c4fa5a35b4a0feae1b920"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE scores are low because there is very little word-for-word overlap.\n",
            "ROUGE-L Score: 0.3636\n",
            "---------------------------------------------- \n",
            "\n",
            "--- Evaluating with BLEU (Lexical Precision) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e0fb29376aa4949b6890561c9495a97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3de9e1b29ac34fef9d4105093cad6977"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb0194b39486497195c1fd8c86c30787"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score is also low, as it relies on matching n-grams (phrases).\n",
            "BLEU Score: 0.0000\n",
            "------------------------------------------------- \n",
            "\n",
            "--- Evaluating with BERTScore (Semantic Similarity) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2347b66f3c74b8ea4ae0059a24ad5f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52253fc37c124746a27b1aa612e7872d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b17cd9d6ab644cdca7393d41888c7505"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "563e113b046a4aeaa9b4dcefe43603bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5b459622b8e428bac98feb33820302b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d66efecc13a4df29b4a0568b0c6f3d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore understands that 'durable' is similar to 'long-lasting' and 'jacket' is similar to 'coat'.\n",
            "BERTScore F1-Score: 0.8906\n",
            "------------------------------------------------------- \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CeLDk_qg7vnP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}